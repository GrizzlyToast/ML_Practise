{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GrizzlyToast/ML_Practise/blob/main/COMP551_assignment4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lz8XQPDJ8rfW"
      },
      "source": [
        "#Acquire the Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DYxQer9ThtAb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a0b12c9-8c20-4122-ce9e-a41ec499d245"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: unidecode in /usr/local/lib/python3.12/dist-packages (1.4.0)\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.12/dist-packages (4.4.0)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.12/dist-packages (from gensim) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from gensim) (1.16.3)\n",
            "Requirement already satisfied: smart_open>=1.8.1 in /usr/local/lib/python3.12/dist-packages (from gensim) (7.5.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from smart_open>=1.8.1->gensim) (2.0.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install unidecode\n",
        "!pip install gensim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EMGgxrXkcP2G"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PuFQSICo8sIL",
        "outputId": "167b4f59-951d-4d65-fa60-a37796d5f82f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "drive.mount('/content/drive')\n",
        "data_path = '/content/drive/My Drive/COMP551/data/WOS/WOS11967/'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "from unidecode import unidecode\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.optim import AdamW\n",
        "import string\n",
        "from collections import Counter\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from transformers import BertTokenizer, BertModel, get_linear_schedule_with_warmup\n",
        "import gensim\n",
        "from gensim.models import Word2Vec\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n"
      ],
      "metadata": {
        "id": "GYLnufRo5OZD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5f9f66c8-c149-44a1-8a10-bc2b8b5c3322"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Name tf.RaggedTensorSpec has already been registered for class tensorflow.python.ops.ragged.ragged_tensor.RaggedTensorSpec.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-226161470.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBertTokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBertModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_linear_schedule_with_warmup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgensim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgensim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mWord2Vec\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_handle_fromlist\u001b[0;34m(module, fromlist, import_, recursive)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/utils/import_utils.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   2315\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_class_to_module\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2316\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2317\u001b[0;31m                 \u001b[0mmodule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_class_to_module\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2318\u001b[0m                 \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2319\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mModuleNotFoundError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/utils/import_utils.py\u001b[0m in \u001b[0;36m_get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   2345\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmodule_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2346\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2347\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2348\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2349\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/utils/import_utils.py\u001b[0m in \u001b[0;36m_get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   2343\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodule_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2344\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2345\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmodule_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2346\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2347\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/importlib/__init__.py\u001b[0m in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m     88\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m             \u001b[0mlevel\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_bootstrap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gcd_import\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m...\u001b[0m\u001b[0mgeneration\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGenerationMixin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m...\u001b[0m\u001b[0mmodeling_attn_mask_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_prepare_4d_attention_mask_for_sdpa\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_prepare_4d_causal_attention_mask_for_sdpa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m...\u001b[0m\u001b[0mmodeling_layers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGradientCheckpointingLayer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m from ...modeling_outputs import (\n\u001b[1;32m     34\u001b[0m     \u001b[0mBaseModelOutputWithPastAndCrossAttentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/modeling_layers.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     26\u001b[0m )\n\u001b[1;32m     27\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAutoModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mprocessing_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mUnpack\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTransformersKwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauto_docstring\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcan_return_tuple\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogging\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/processing_utils.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mimage_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mChannelDimension\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mImageInput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_vision_available\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchat_template_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrender_jinja_template\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mvideo_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mVideoInput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVideoMetadata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/video_utils.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mimage_transforms\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPaddingMode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_channel_dimension_format\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mimage_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mChannelDimension\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfer_channel_dimension_format\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_valid_image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m from .utils import (\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/image_transforms.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mis_tf_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m     \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mis_flax_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0m_tf2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m__internal__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m__operators__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0maudio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/_api/v2/__internal__/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__internal__\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdecorator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__internal__\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdispatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__internal__\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdistribute\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__internal__\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0meager_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__internal__\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfeature_column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/_api/v2/__internal__/distribute/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msys\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_sys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__internal__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__internal__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0minterim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__internal__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmulti_process_runner\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/_api/v2/__internal__/distribute/combinations/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msys\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_sys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcombinations\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0menv\u001b[0m \u001b[0;31m# line: 456\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcombinations\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgenerate\u001b[0m \u001b[0;31m# line: 365\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcombinations\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0min_main_process\u001b[0m \u001b[0;31m# line: 418\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/distribute/combinations.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcollective_all_reduce_strategy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdistribute_lib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmulti_process_runner\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/distribute/collective_all_reduce_strategy.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotobuf\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow_server_pb2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcollective_util\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcross_device_ops\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcross_device_ops_lib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcross_device_utils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdevice_util\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/distribute/cross_device_ops.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdevice_lib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcollective_util\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcross_device_utils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdevice_util\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdistribute_utils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/distribute/cross_device_utils.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcollective_util\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mvalues\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mvalue_lib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meager\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbackprop_util\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meager\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/distribute/values.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotobuf\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mstruct_pb2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdevice_util\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdistribute_lib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpacked_distributed_variable\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpacked\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mreduce_util\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mag_ctx\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mautograph_ctx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimpl\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mapi\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mautograph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdataset_ops\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    206\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcollective_util\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdevice_util\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/data/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;31m# pylint: disable=unused-import\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mexperimental\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset_ops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAUTOTUNE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset_ops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/data/experimental/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;31m# pylint: disable=unused-import\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mservice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatching\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdense_to_ragged_batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatching\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdense_to_sparse_batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/data/experimental/service/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    417\u001b[0m \"\"\"\n\u001b[1;32m    418\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 419\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_service_ops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdistribute\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    420\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_service_ops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfrom_dataset_id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    421\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_service_ops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mregister_dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/data/experimental/ops/data_service_ops.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotobuf\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdata_service_pb2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtf2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcompression_ops\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mservice\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_pywrap_server_lib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mservice\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_pywrap_utils_exp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/data/experimental/ops/compression_ops.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# ==============================================================================\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\"\"\"Ops for compressing and uncompressing dataset elements.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mstructure\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgen_experimental_dataset_ops\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mged_ops\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/data/util/structure.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mresource_variable_ops\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensor_array_ops\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mragged\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mragged_tensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplatform\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtf_logging\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mlogging\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtypes\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0minternal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/ops/ragged/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0mAPI\u001b[0m \u001b[0mdocstring\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mragged\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \"\"\"\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mragged\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mragged_tensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/ops/ragged/ragged_tensor.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m   2318\u001b[0m \u001b[0;31m# ===============================================================================\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2319\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0mtf_export\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"RaggedTensorSpec\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2320\u001b[0;31m \u001b[0;34m@\u001b[0m\u001b[0mtype_spec_registry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"tf.RaggedTensorSpec\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2321\u001b[0m class RaggedTensorSpec(\n\u001b[1;32m   2322\u001b[0m     type_spec.BatchableTypeSpec, internal_types.RaggedTensorSpec):\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/framework/type_spec_registry.py\u001b[0m in \u001b[0;36mdecorator_fn\u001b[0;34m(cls)\u001b[0m\n\u001b[1;32m     57\u001b[0m                        (cls.__module__, cls.__name__, _TYPE_SPEC_TO_NAME[cls]))\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_NAME_TO_TYPE_SPEC\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m       raise ValueError(\"Name %s has already been registered for class %s.%s.\" %\n\u001b[0m\u001b[1;32m     60\u001b[0m                        (name, _NAME_TO_TYPE_SPEC[name].__module__,\n\u001b[1;32m     61\u001b[0m                         _NAME_TO_TYPE_SPEC[name].__name__))\n",
            "\u001b[0;31mValueError\u001b[0m: Name tf.RaggedTensorSpec has already been registered for class tensorflow.python.ops.ragged.ragged_tensor.RaggedTensorSpec."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_LENGTH = 405"
      ],
      "metadata": {
        "id": "E1fWpJl2kTwx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Load WOS Dataset\n",
        "\n",
        "This cell imports the textual data from the WOS dataset, parses it into words and creates meaningful word embeddings for the LSTM and BERT models to use."
      ],
      "metadata": {
        "id": "eYxY97U2maw9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load WOS Dataset\n",
        "def load_data(data_path):\n",
        "    \"\"\"\n",
        "    Returns list of sentences for the input text and labels from files contained within data_path.\n",
        "    \"\"\"\n",
        "    all_filenames = glob.glob(data_path + '*.txt')\n",
        "    filepaths = {}\n",
        "    for name in all_filenames:\n",
        "        filepaths[name.split('/')[-1].split('.')[0]] = name\n",
        "\n",
        "    with open(filepaths['X'], 'r') as f:\n",
        "        text = [unidecode(line) for line in f.read().splitlines()]\n",
        "    with open(filepaths['YL1'], 'r') as f:\n",
        "        labels_l1 = [int(line) for line in f.read().splitlines()]\n",
        "    with open(filepaths['YL2'], 'r') as f:\n",
        "        labels_l2 = [int(line) for line in f.read().splitlines()]\n",
        "\n",
        "    return text, labels_l1, labels_l2\n",
        "\n",
        "\n",
        "\n",
        "def build_vocab(texts, max_vocab_size=10000):\n",
        "    \"\"\"\n",
        "    Creates a vocabulary from a list of texts. It counts word frequencies, selects the most\n",
        "    common words up to max_vocab_size, and assigns unique integer IDs to each word, including\n",
        "    special tokens for padding (<PAD>) and unknown words (<UNK>).\n",
        "    \"\"\"\n",
        "    word_counts = Counter()\n",
        "    for text in texts:\n",
        "        words = text.lower().split()\n",
        "        word_counts.update(words) # create a list of tuples(word, frequency)\n",
        "\n",
        "    most_common = word_counts.most_common(max_vocab_size - 2) # reduces the list of tuples( word, frequency) to the \"max_vocab_size\" most common words\n",
        "    vocab = {'<PAD>': 0, '<UNK>': 1}\n",
        "    for i, (word, _) in enumerate(most_common):\n",
        "        vocab[word] = i + 2 # creates a dictionary mapping the integer IDs to the most common words\n",
        "\n",
        "    return vocab\n",
        "\n",
        "def train_word2vec_on_corpus(texts, embedding_dim, window):\n",
        "    \"\"\"\n",
        "    Trains a Word2Vec model (using the Skip-Gram algorithm) on the provided text corpus. It\n",
        "    generates word embeddings, which are dense vector representations of words, based on\n",
        "    their context.\n",
        "    \"\"\"\n",
        "    # Creates an array of sentences, each sentence is a list of words\n",
        "    sentences = [text.lower().split() for text in texts]\n",
        "\n",
        "    # Uses Skip-Gram for geenrating word embeddings, can also set sg = 0 to use CBOW instead\n",
        "    model = Word2Vec(\n",
        "        sentences=sentences,\n",
        "        vector_size=embedding_dim,\n",
        "        window=window,\n",
        "        min_count=0,\n",
        "        workers=8,\n",
        "        epochs=10,\n",
        "        sg = 1\n",
        "    )\n",
        "\n",
        "    print(f\"Trained Word2Vec with vocabulary of {len(model.wv)} words\")\n",
        "    return model.wv\n",
        "\n",
        "def build_embedding_matrix(vocab, word2vec_wv, embedding_dim):\n",
        "    \"\"\"\n",
        "    This function constructs an embedding matrix for the vocabulary. It populates this matrix\n",
        "    with pre-trained Word2Vec embeddings for words found in the vocabulary and initializes\n",
        "    out-of-vocabulary words with small random values. It also prints the percentage of\n",
        "    successfully found word embeddings from Word2Vec\n",
        "    \"\"\"\n",
        "    vocab_size = len(vocab)\n",
        "    embedding_matrix = np.random.randn(vocab_size, embedding_dim) * 0.01\n",
        "\n",
        "    # PAD token should be zeros\n",
        "    embedding_matrix[0] = np.zeros(embedding_dim)\n",
        "\n",
        "    # Copy word embeddings from Word2Vec into embedding matrix (words not found are left with random embedding)\n",
        "    found = 0\n",
        "    for word, idx in vocab.items():\n",
        "        if word in word2vec_wv:\n",
        "            embedding_matrix[idx] = word2vec_wv[word]\n",
        "            found += 1\n",
        "\n",
        "    coverage = 100 * found / vocab_size\n",
        "    print(f\"Embedding coverage:{coverage:.1f}%\") #\n",
        "\n",
        "    return embedding_matrix\n",
        "\n",
        "def text_to_indices(text, vocab, max_len=405):\n",
        "  \"\"\"\n",
        "  Converts a string of text into a list of indicies with a vocab ({word:int}) as reference. Furthermore,\n",
        "  sequences are truncated to max_len in order to ensure all sequences haved a fixed length.\n",
        "  \"\"\"\n",
        "    words = text.lower().split()[:max_len]\n",
        "\n",
        "    # Fetches index of known or unkown word\n",
        "    indices = [vocab.get(word, vocab['<UNK>']) for word in words]\n",
        "\n",
        "    if len(indices) < max_len:\n",
        "        indices += [vocab['<PAD>']] * (max_len - len(indices))\n",
        "\n",
        "    return indices"
      ],
      "metadata": {
        "id": "dw2xe-LHmeU9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Defining the WOSDataset classes\n"
      ],
      "metadata": {
        "id": "PCGTgQIVnFIe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class WOSDataset(Dataset):\n",
        "    \"\"\"\n",
        "    This class is a custom PyTorch Dataset for LSTM models. It prepares data samples,\n",
        "    converting text to numerical indices and providing corresponding labels. It's designed\n",
        "    to work with DataLoader for efficient batching.\n",
        "    \"\"\"\n",
        "    def __init__(self, texts, labels, vocab, max_len=MAX_LENGTH):\n",
        "        self.texts = texts\n",
        "        self.labels = labels\n",
        "        self.vocab = vocab\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = self.texts[idx]\n",
        "        label = self.labels[idx]\n",
        "        indices = text_to_indices(text, self.vocab, self.max_len)\n",
        "        return torch.tensor(indices, dtype=torch.long), torch.tensor(label, dtype=torch.long)\n",
        "\n",
        "class WOSDatasetBERT(Dataset):\n",
        "    \"\"\"\n",
        "    Similar to WOSDataset, but tailored for BERT models. It uses a BertTokenizer to\n",
        "    tokenize and encode text, adding special tokens, padding, and attention masks required\n",
        "    by BERT.\n",
        "    \"\"\"\n",
        "    def __init__(self, texts, labels, tokenizer, max_len=MAX_LENGTH):\n",
        "        self.texts = texts\n",
        "        self.labels = labels\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = self.texts[idx]\n",
        "        label = self.labels[idx]\n",
        "\n",
        "        encoding = self.tokenizer.encode_plus(\n",
        "            text,\n",
        "            add_special_tokens=True,\n",
        "            max_length=self.max_len,\n",
        "            padding='max_length',\n",
        "            truncation=True,\n",
        "            return_attention_mask=True,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "\n",
        "        return {\n",
        "            'input_ids': encoding['input_ids'].flatten(),\n",
        "            'attention_mask': encoding['attention_mask'].flatten(),\n",
        "            'labels': torch.tensor(label, dtype=torch.long)\n",
        "        }\n"
      ],
      "metadata": {
        "id": "hdeVkbZInBWY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Defining the models\n",
        "\n",
        "This section defines the model architectures for LSTM and BERT models, and also defines the helper functions required to train the models and fit the data."
      ],
      "metadata": {
        "id": "ZZ6oV73unc4S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##LSTM cell class"
      ],
      "metadata": {
        "id": "q0l2-Lwynn2Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LSTMCell(nn.Module):\n",
        "\n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        super(LSTMCell, self).__init__()\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        # Forget gate\n",
        "        self.W_f = nn.Parameter(torch.randn(hidden_size, input_size + hidden_size) * 0.01)\n",
        "        self.b_f = nn.Parameter(torch.zeros(hidden_size))\n",
        "\n",
        "        # Input gate\n",
        "        self.W_i = nn.Parameter(torch.randn(hidden_size, input_size + hidden_size) * 0.01)\n",
        "        self.b_i = nn.Parameter(torch.zeros(hidden_size))\n",
        "\n",
        "        # Candidate gate\n",
        "        self.W_c = nn.Parameter(torch.randn(hidden_size, input_size + hidden_size) * 0.01)\n",
        "        self.b_c = nn.Parameter(torch.zeros(hidden_size))\n",
        "\n",
        "        # Output gate\n",
        "        self.W_o = nn.Parameter(torch.randn(hidden_size, input_size + hidden_size) * 0.01)\n",
        "        self.b_o = nn.Parameter(torch.zeros(hidden_size))\n",
        "\n",
        "    def forward(self, x, h_prev, c_prev):\n",
        "        combined = torch.cat([x, h_prev], dim=1)\n",
        "\n",
        "        f_t = torch.sigmoid(combined @ self.W_f.t() + self.b_f)\n",
        "        i_t = torch.sigmoid(combined @ self.W_i.t() + self.b_i)\n",
        "        c_tilde = torch.tanh(combined @ self.W_c.t() + self.b_c)\n",
        "        c_t = f_t * c_prev + (i_t * c_tilde)\n",
        "        o_t = torch.sigmoid(combined @ self.W_o.t() + self.b_o)\n",
        "        h_t = o_t * torch.tanh(c_t)\n",
        "\n",
        "        return h_t, c_t\n"
      ],
      "metadata": {
        "id": "IxarLhiYoNGx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##LSTM model class"
      ],
      "metadata": {
        "id": "buOx5CBToSEb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LSTMModel(nn.Module):\n",
        "\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_size, num_classes, embedding_matrix=None, freeze_embeddings=False, num_layers=1, dropout=0.5):\n",
        "        super(LSTMModel, self).__init__()\n",
        "        self.vocab_size = vocab_size\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_classes = num_classes\n",
        "        self.num_layers = num_layers\n",
        "        self.dropout_rate = dropout\n",
        "\n",
        "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "        print(\"Using:\", self.device)\n",
        "\n",
        "\n",
        "        # Embedding layer\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
        "\n",
        "        if embedding_matrix is not None:\n",
        "            # Load pre-trained Word2Vec embeddings\n",
        "            self.embedding.weight = nn.Parameter(torch.FloatTensor(embedding_matrix))\n",
        "            print(\"Loaded Word2Vec embeddings: \", embedding_matrix.shape)\n",
        "\n",
        "        # Freeze embeddings if desired\n",
        "        self.embedding.weight.requires_grad = not freeze_embeddings\n",
        "        if freeze_embeddings:\n",
        "            print(\"Embeddings are frozen during training\")\n",
        "\n",
        "\n",
        "        self.lstm_cells = nn.ModuleList()\n",
        "\n",
        "        # First layer\n",
        "        self.lstm_cells.append(LSTMCell(embedding_dim, hidden_size))\n",
        "\n",
        "        # Remaining layers\n",
        "        for _ in range(1, num_layers):\n",
        "            self.lstm_cells.append(LSTMCell(hidden_size, hidden_size))\n",
        "\n",
        "        # Dropout between LSTM layers\n",
        "        if num_layers > 1:\n",
        "            self.dropout_layers = nn.ModuleList([nn.Dropout(dropout) for _ in range(num_layers - 1)])\n",
        "        else:\n",
        "            self.dropout_layers = nn.ModuleList()\n",
        "\n",
        "        # Dropout before final classification layer\n",
        "        self.fc_dropout = nn.Dropout(dropout)\n",
        "\n",
        "        self.fc = nn.Linear(hidden_size, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        batch_size, seq_len = x.size()\n",
        "\n",
        "        embedded = self.embedding(x)\n",
        "\n",
        "        # Initialize hidden and cell states\n",
        "        h = [torch.zeros(batch_size, self.hidden_size, device=x.device) for _ in range(self.num_layers)]\n",
        "        c = [torch.zeros(batch_size, self.hidden_size, device=x.device) for _ in range(self.num_layers)]\n",
        "\n",
        "        # Process sequence\n",
        "        for t in range(seq_len):\n",
        "            x_t = embedded[:, t, :]\n",
        "\n",
        "            for layer in range(self.num_layers):\n",
        "                if layer == 0:\n",
        "                    h[layer], c[layer] = self.lstm_cells[layer](x_t, h[layer], c[layer])\n",
        "                else:\n",
        "                    # Apply dropout to the output from the previous layer\n",
        "                    h_input = self.dropout_layers[layer-1](h[layer-1]) if self.training else h[layer-1]\n",
        "                    h[layer], c[layer] = self.lstm_cells[layer](h_input, h[layer], c[layer])\n",
        "\n",
        "        # Apply dropout before final classification layer\n",
        "        h_final = self.fc_dropout(h[-1])\n",
        "\n",
        "        # Final classification\n",
        "        output = self.fc(h_final)\n",
        "        return output\n",
        "\n",
        "\n",
        "\n",
        "    def fit(self, train_loader, val_loader=None, epochs=10, lr=0.001):\n",
        "\n",
        "        self.to(self.device)\n",
        "\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "        optimizer = torch.optim.Adam(self.parameters(), lr=lr)\n",
        "\n",
        "        train_losses = []\n",
        "        train_accuracies = []\n",
        "        val_accuracies = []\n",
        "\n",
        "        for epoch in range(epochs):\n",
        "            self.train()\n",
        "            epoch_loss = 0\n",
        "\n",
        "            for batch_x, batch_y in train_loader:\n",
        "                batch_x = batch_x.to(self.device)\n",
        "                batch_y = batch_y.to(self.device)\n",
        "\n",
        "                # Forward pass\n",
        "                outputs = self.forward(batch_x)\n",
        "                loss = criterion(outputs, batch_y)\n",
        "\n",
        "                # Backward pass\n",
        "                optimizer.zero_grad()\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "                epoch_loss += loss.item()\n",
        "\n",
        "            avg_loss = epoch_loss / len(train_loader)\n",
        "            train_losses.append(avg_loss)\n",
        "\n",
        "            # Training\n",
        "            train_acc = self.evaluate_acc(train_loader)\n",
        "            train_accuracies.append(train_acc)\n",
        "\n",
        "            # Validation\n",
        "            val_acc = self.evaluate_acc(val_loader)\n",
        "            val_accuracies.append(val_acc)\n",
        "            print(f'Epoch {epoch+1}/{epochs}, Loss: {avg_loss:.4f}, Train Acc: {train_acc:.4f}, Val Acc: {val_acc:.4f}')\n",
        "\n",
        "\n",
        "        return train_losses, train_accuracies, val_accuracies\n",
        "\n",
        "    def predict(self, data_loader):\n",
        "        self.eval()\n",
        "        predictions = []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for batch_x, _ in data_loader:\n",
        "                batch_x = batch_x.to(self.device)\n",
        "                outputs = self.forward(batch_x)\n",
        "                _, predicted = torch.max(outputs, 1)\n",
        "                predictions.extend(predicted.cpu().numpy())\n",
        "\n",
        "        return np.array(predictions)\n",
        "\n",
        "    def evaluate_acc(self, data_loader):\n",
        "        self.eval()\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for batch_x, batch_y in data_loader:\n",
        "                batch_x = batch_x.to(self.device)\n",
        "                batch_y = batch_y.to(self.device)\n",
        "\n",
        "                outputs = self.forward(batch_x)\n",
        "                _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "                total += batch_y.size(0)\n",
        "                correct += (predicted == batch_y).sum().item()\n",
        "\n",
        "        accuracy = correct / total\n",
        "        return accuracy\n",
        "\n",
        "\n",
        "def train_lstm_model(X_train, y_train, X_val, y_val, vocab, word2vec_wv, num_classes,\n",
        "                     embedding_dim, hidden_size=128, batch_size=128, epochs=10, lr = 0.001,\n",
        "                     num_layers = 1, freeze_embeddings = True, dropout = 0.3):\n",
        "\n",
        "    torch.manual_seed(11)\n",
        "    np.random.seed(11)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed(11)\n",
        "        torch.cuda.manual_seed_all(11)\n",
        "\n",
        "\n",
        "    # Build embedding matrix from Word2Vec\n",
        "    embedding_matrix = build_embedding_matrix(vocab, word2vec_wv, embedding_dim)\n",
        "\n",
        "\n",
        "    train_dataset = WOSDataset(X_train, y_train, vocab)\n",
        "    val_dataset = WOSDataset(X_val, y_val, vocab)\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "    model = LSTMModel(\n",
        "        vocab_size=len(vocab),\n",
        "        embedding_dim=embedding_dim,\n",
        "        hidden_size=hidden_size,\n",
        "        num_classes=num_classes,\n",
        "        embedding_matrix=embedding_matrix,\n",
        "        freeze_embeddings=freeze_embeddings,\n",
        "        num_layers=num_layers,\n",
        "        dropout=dropout\n",
        "    )\n",
        "\n",
        "    print(f\"Training LSTM model\")\n",
        "    train_losses, train_accuracies, val_accuracies = model.fit(train_loader, val_loader, epochs=epochs, lr=lr)\n",
        "\n",
        "    return model, train_losses, train_accuracies, val_accuracies\n"
      ],
      "metadata": {
        "id": "mxYREAu46HmH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222
        },
        "outputId": "403e0ce9-3c23-41a9-b141-8d425639a51e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'nn' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-4263916404.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mLSTMModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocab_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membedding_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membedding_matrix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfreeze_embeddings\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_layers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdropout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLSTMModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvocab_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'nn' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##BERT Class"
      ],
      "metadata": {
        "id": "8mGimCb9pIuQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BERTClassifier(nn.Module):\n",
        "    def __init__(self, num_classes, dropout, epochs, learning_rate):\n",
        "        super(BERTClassifier, self).__init__()\n",
        "\n",
        "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "        print(\"Using device:\", self.device)\n",
        "\n",
        "        self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.fc = nn.Linear(self.bert.config.hidden_size, num_classes)\n",
        "        self.epochs = epochs\n",
        "        self.learning_rate = learning_rate\n",
        "\n",
        "    def forward(self, input_ids, attention_mask, return_attention=False):\n",
        "        outputs = self.bert(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            output_attentions=return_attention\n",
        "        )\n",
        "\n",
        "        pooled_output = outputs.pooler_output\n",
        "        output = self.dropout(pooled_output)\n",
        "        logits = self.fc(output)\n",
        "\n",
        "        if return_attention:\n",
        "            return logits, outputs.attentions\n",
        "        return logits\n",
        "\n",
        "\n",
        "    def fit(self, train_loader, val_loader, epochs, lr):\n",
        "        self.to(self.device)\n",
        "\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "        optimizer = AdamW(self.parameters(), lr)\n",
        "\n",
        "        total_steps = len(train_loader) * epochs\n",
        "        scheduler = get_linear_schedule_with_warmup(\n",
        "            optimizer,\n",
        "            num_warmup_steps=0,\n",
        "            num_training_steps=total_steps\n",
        "        )\n",
        "\n",
        "        train_losses = []\n",
        "        all_losses = []\n",
        "        val_accuracies = []\n",
        "        train_accuracies = []\n",
        "\n",
        "        for epoch in range(epochs):\n",
        "            self.train()\n",
        "            epoch_loss = 0\n",
        "\n",
        "\n",
        "            for batch_idx, batch in enumerate(train_loader):\n",
        "\n",
        "                input_ids = batch['input_ids'].to(self.device)\n",
        "                attention_mask = batch['attention_mask'].to(self.device)\n",
        "                labels = batch['labels'].to(self.device)\n",
        "\n",
        "                # Forward pass\n",
        "                outputs = self.forward(input_ids, attention_mask)\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "                # Backward pass\n",
        "                optimizer.zero_grad()\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "                scheduler.step()\n",
        "\n",
        "                epoch_loss += loss.item()\n",
        "\n",
        "                all_losses.append(loss.item())\n",
        "\n",
        "                if batch_idx % 50 == 0:\n",
        "                    print(f\"    Batch {batch_idx}/{len(train_loader)}, Loss: {loss.item():.4f}\")\n",
        "\n",
        "            avg_loss = epoch_loss / len(train_loader)\n",
        "            train_losses.append(avg_loss)\n",
        "\n",
        "            val_acc = self.evaluate_acc(val_loader)\n",
        "            val_accuracies.append(val_acc)\n",
        "\n",
        "            train_acc = self.evaluate_acc(train_loader)\n",
        "            train_accuracies.append(train_acc)\n",
        "\n",
        "            print(f'Epoch {epoch+1}/{epochs}, Loss: {avg_loss:.4f}, Train Acc: {train_acc:.4f}, Val Acc: {val_acc:.4f}')\n",
        "\n",
        "        return all_losses, train_losses, val_accuracies, train_accuracies\n",
        "\n",
        "    def predict(self, data_loader):\n",
        "        self.eval()\n",
        "        predictions = []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for batch in data_loader:\n",
        "                input_ids = batch['input_ids'].to(self.device)\n",
        "                attention_mask = batch['attention_mask'].to(self.device)\n",
        "\n",
        "                outputs = self.forward(input_ids, attention_mask)\n",
        "                _, predicted = torch.max(outputs, 1)\n",
        "                predictions.extend(predicted.cpu().numpy())\n",
        "\n",
        "        return np.array(predictions)\n",
        "\n",
        "    def evaluate_acc(self, data_loader):\n",
        "        self.eval()\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for batch in data_loader:\n",
        "                input_ids = batch['input_ids'].to(self.device)\n",
        "                attention_mask = batch['attention_mask'].to(self.device)\n",
        "                labels = batch['labels'].to(self.device)\n",
        "\n",
        "                outputs = self.forward(input_ids, attention_mask)\n",
        "                _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "                total += labels.size(0)\n",
        "                correct += (predicted == labels).sum().item()\n",
        "\n",
        "        accuracy = correct / total\n",
        "        return accuracy\n",
        "\n",
        "def train_bert_model(X_train, y_train, X_val, y_val, num_classes, batch_size, epochs, learning_rate, dropout):\n",
        "\n",
        "    import gc\n",
        "\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.empty_cache()\n",
        "        gc.collect()\n",
        "        print(\"CUDA cache cleared\")\n",
        "\n",
        "    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "    train_dataset = WOSDatasetBERT(X_train, y_train, tokenizer)\n",
        "    val_dataset = WOSDatasetBERT(X_val, y_val, tokenizer)\n",
        "\n",
        "    train_loader = DataLoader(\n",
        "        train_dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=True,\n",
        "        num_workers=0,\n",
        "        pin_memory=False\n",
        "    )\n",
        "    val_loader = DataLoader(\n",
        "        val_dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=False,\n",
        "        num_workers=0,\n",
        "        pin_memory=False\n",
        "    )\n",
        "\n",
        "    model = BERTClassifier(num_classes=num_classes, dropout=dropout, epochs=epochs, learning_rate=learning_rate)\n",
        "\n",
        "    print(\"Training BERT model\")\n",
        "\n",
        "    all_losses, train_losses, val_accuracies, train_accuracies = model.fit(train_loader, val_loader, epochs=epochs, lr=learning_rate)\n",
        "\n",
        "    return model, train_loader, val_loader, tokenizer, all_losses, train_losses, val_accuracies, train_accuracies"
      ],
      "metadata": {
        "id": "XFgp4HeBpEAT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(model, test_loader, model_type='LSTM'):\n",
        "    if model_type == 'LSTM':\n",
        "        y_true = []\n",
        "        for _, labels in test_loader:\n",
        "            y_true.extend(labels.numpy())\n",
        "    else:\n",
        "        y_true = []\n",
        "        for batch in test_loader:\n",
        "            y_true.extend(batch['labels'].numpy())\n",
        "\n",
        "    y_pred = model.predict(test_loader)\n",
        "    accuracy = accuracy_score(y_true, y_pred)\n",
        "\n",
        "    return accuracy, y_true, y_pred"
      ],
      "metadata": {
        "id": "y42KSJWC0ECd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Statistics on the dataset\n",
        "\n",
        "In this section we look at how the length of the abstracts are distributed, in order to pick a reasonable length for the word embeddings such that less padding is necessary while still choosing a size that can fully containt most of the abstracts while only rejecting the outliers."
      ],
      "metadata": {
        "id": "7Dg_agfCpU_9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xbxeRz4kIgk_"
      },
      "outputs": [],
      "source": [
        "#data cleaning to reduce size of letter vocabulary, unidecode to transform strings to ascii letters\n",
        "\n",
        "all_filenames = glob.glob(data_path + '*.txt') #get all text files\n",
        "#print(all_filenames)\n",
        "filepaths = {}\n",
        "for name in all_filenames:\n",
        "  filepaths[name.split('/')[-1].split('.')[0]] = name\n",
        "\n",
        "# define data and class labels\n",
        "with open(filepaths['X'], 'r') as f:\n",
        "    text = [unidecode(line) for line in f.read().splitlines()] #Notice decode to ascii in this line\n",
        "with open(filepaths['YL1'], 'r') as f:\n",
        "    labels_parent = [line.split('\\n') for line in f.read().splitlines()]\n",
        "with open(filepaths['YL2'], 'r') as f:\n",
        "    labels_child = [line.split('\\n') for line in f.read().splitlines()]\n",
        "\n",
        "#This dataset should contain 11,967 documents\n",
        "#print(len(text), len(labels_parent), len(labels_child))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import statistics\n",
        "import matplotlib.pyplot as plt\n",
        "abstracts = [abst.split() for abst in text]\n",
        "\n",
        "max_length = max(len(abstract) for abstract in abstracts)\n",
        "min_length = min(len(abstract) for abstract in abstracts)\n",
        "average_length = sum(len(abstract) for abstract in abstracts) / len(abstracts)\n",
        "median_length = statistics.median(len(abstract) for abstract in abstracts)\n",
        "std_length = statistics.stdev(len(abstract) for abstract in abstracts)\n",
        "\n",
        "print(f\"Max length: {max_length}, Min length: {min_length}, Average length: {average_length}, Standard deviation: {std_length}, Median length: {median_length} \")\n",
        "\n",
        "plt.hist([len(abstract) for abstract in abstracts], bins=100)\n",
        "plt.xlabel('Abstract length')\n",
        "plt.ylabel('Frequency')\n",
        "plt.title('Abstract length distribution')\n",
        "plt.show()\n",
        "\n",
        "print(np.percentile(np.array([len(abstract) for abstract in abstracts]), 99)"
      ],
      "metadata": {
        "id": "TvDTkpYp44zA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 490
        },
        "outputId": "4c4c39d4-7a2f-45d9-fa92-36d1a6b78b78"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Max length: 906, Min length: 22, Average length: 195.16921534219102, Standard deviation: 70.80644575931885, Median length: 189 \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "percentiles = [95, 99, 99.9, 99.99]\n",
        "percentiles_values = [np.percentile(np.array([len(abstract) for abstract in abstracts]), percentile) for percentile in percentiles]\n",
        "for i in range(4):\n",
        "  print(f\"{percentiles[i]}%: {percentiles_values[i]}\")\n",
        "#print(f\"percentiles{(percentiles, percentiles_values) for i in range(4)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bWg9otbf9fo4",
        "outputId": "a85cba5e-e5f5-45be-b38a-61b4dca64bb8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "95%: 319.0\n",
            "99%: 407.0\n",
            "99.9%: 569.1020000000044\n",
            "99.99%: 713.0339999999887\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Execution"
      ],
      "metadata": {
        "id": "nq3N9qyL6Ugc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_path = \"WebOfScience/WOS11967/\"\n",
        "\n",
        "texts, labels_l1, labels_l2, merged_labels = load_data(data_path)\n",
        "print(f\"Loaded {len(texts)} documents\")\n",
        "print(f\"YL1 classes: {len(set(labels_l1))}, YL2 classes: {len(set(labels_l2))}\")\n",
        "print(f\"Merged Y classes: {len(set(merged_labels))}\")\n",
        "\n",
        "\n",
        "# Create word embeddings for all available data\n",
        "sentences = [clean_text(t) for t in texts]\n",
        "print(\"Number of sentences for embeddings:\", len(sentences))\n"
      ],
      "metadata": {
        "id": "RYqVZr5f6YIj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train Word2Vec on corpus\n",
        "print(\"Training Word2Vec on WOS corpus\")\n",
        "print(\"Uses skip-gram\")\n",
        "embedding_dim = 150\n",
        "word2vec_wv = train_word2vec_on_corpus(sentences, embedding_dim=embedding_dim, window=6)\n",
        "\n"
      ],
      "metadata": {
        "id": "zco6zT3w6d6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_temp, y_train_l1, y_temp_l1, y_train_l2, y_temp_l2, y_train_combo, y_temp_combo = train_test_split(\n",
        "    sentences, labels_l1, labels_l2, merged_labels,\n",
        "    test_size=0.3,\n",
        "    random_state=11,\n",
        "    stratify=labels_l1\n",
        ")\n",
        "\n",
        "X_val, X_test, y_val_l1, y_test_l1, y_val_l2, y_test_l2, y_val_combo, y_test_combo = train_test_split(\n",
        "    X_temp, y_temp_l1, y_temp_l2, y_temp_combo,\n",
        "    test_size=0.333,\n",
        "    random_state=11,\n",
        "    stratify=y_temp_l1\n",
        ")\n",
        "\n",
        "print(f\"Train size: {len(X_train)} ({len(X_train)/len(texts)*100:.1f}%)\")\n",
        "print(f\"Val size: {len(X_val)} ({len(X_val)/len(texts)*100:.1f}%)\")\n",
        "print(f\"Test size: {len(X_test)} ({len(X_test)/len(texts)*100:.1f}%)\")"
      ],
      "metadata": {
        "id": "VfYCLuch6fsf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from itertools import islice\n",
        "\n",
        "print(f\"Train: {len(X_train)}, Val: {len(X_val)}\")\n",
        "\n",
        "\n",
        "print(\"Building vocabulary:\")\n",
        "vocab = build_vocab(X_train)\n",
        "print(\"Vocabulary size:\", len(vocab))\n",
        "\n",
        "# for key, value in islice(vocab.items(), 150):\n",
        "#     print(f\"Key: {key}, Value: {value}\")"
      ],
      "metadata": {
        "id": "dOrQ8qZ_f1d4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LSTM Grid Search and Training\n"
      ],
      "metadata": {
        "id": "oVIAa8ucgv_I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import itertools\n",
        "import pandas as pd\n",
        "\n",
        "print(\"Grid Search for YL1\")\n",
        "# Define hyperparameter grid\n",
        "param_grid = {\n",
        "    'lr': [0.005, 0.009, 0.015],\n",
        "    'num_layers': [1, 2, 3],\n",
        "    'dropout': [0.2, 0.3, 0.5]\n",
        "}\n",
        "\n",
        "# Fixed parameters\n",
        "fixed_params = {\n",
        "    'embedding_dim': embedding_dim,\n",
        "    'hidden_size': 256,\n",
        "    'batch_size': 128,\n",
        "    'epochs': 30,\n",
        "    'freeze_embeddings': True,\n",
        "    'num_classes': len(set(labels_l1))\n",
        "}\n",
        "\n",
        "# Storage for results\n",
        "results = []\n",
        "\n",
        "# Generate all combinations\n",
        "param_combinations = list(itertools.product(\n",
        "    param_grid['lr'],\n",
        "    param_grid['num_layers'],\n",
        "    param_grid['dropout']\n",
        "))\n",
        "\n",
        "total_experiments = len(param_combinations)\n",
        "\n",
        "# Run grid search\n",
        "for idx, (lr, num_layers, dropout) in enumerate(param_combinations, 1):\n",
        "    print(f\"Learning Rate: {lr}\")\n",
        "    print(f\"Num Layers: {num_layers}\")\n",
        "    print(f\"Dropout: {dropout}\")\n",
        "\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "\n",
        "    # Train model\n",
        "\n",
        "    model, train_losses, train_accuracies, val_accuracies = train_lstm_model(\n",
        "        X_train, y_train_l1, X_val, y_val_l1, vocab, word2vec_wv,\n",
        "        num_classes=fixed_params['num_classes'],\n",
        "        embedding_dim=fixed_params['embedding_dim'],\n",
        "        hidden_size=fixed_params['hidden_size'],\n",
        "        batch_size=fixed_params['batch_size'],\n",
        "        epochs=fixed_params['epochs'],\n",
        "        lr=lr,\n",
        "        num_layers=num_layers,\n",
        "        freeze_embeddings=fixed_params['freeze_embeddings'],\n",
        "        dropout=dropout\n",
        "    )\n",
        "\n",
        "\n",
        "    # Get best validation accuracy and corresponding epoch\n",
        "    best_val_acc = max(val_accuracies)\n",
        "    best_epoch = val_accuracies.index(best_val_acc) + 1\n",
        "    final_val_acc = val_accuracies[-1]\n",
        "    final_train_acc = train_accuracies[-1]\n",
        "    final_train_loss = train_losses[-1]\n",
        "\n",
        "    # Store results\n",
        "    result = {\n",
        "        'experiment': idx,\n",
        "        'lr': lr,\n",
        "        'num_layers': num_layers,\n",
        "        'dropout': dropout,\n",
        "        'best_val_acc': best_val_acc,\n",
        "        'best_epoch': best_epoch,\n",
        "        'final_val_acc': final_val_acc,\n",
        "        'final_train_acc': final_train_acc,\n",
        "        'final_train_loss': final_train_loss,\n",
        "        'train_losses': train_losses.copy(),\n",
        "        'train_accuracies': train_accuracies.copy(),\n",
        "        'val_accuracies': val_accuracies.copy(),\n",
        "        'model': model\n",
        "    }\n",
        "\n",
        "    results.append(result)\n",
        "\n",
        "    print(f\"Best Val Acc: {best_val_acc:.4f} (epoch {best_epoch})\")\n",
        "    print(f\"Final Val Acc: {final_val_acc:.4f}\")\n",
        "\n",
        "\n",
        "\n",
        "# Create summary DataFrame\n",
        "summary_df = pd.DataFrame([{\n",
        "    'Experiment': r['experiment'],\n",
        "    'LR': r['lr'],\n",
        "    'Layers': r['num_layers'],\n",
        "    'Dropout': r['dropout'],\n",
        "    'Best Val Acc': r['best_val_acc'],\n",
        "    'Best Epoch': r['best_epoch'],\n",
        "    'Final Val Acc': r['final_val_acc'],\n",
        "    'Final Train Acc': r['final_train_acc']\n",
        "    } for r in results])\n",
        "\n",
        "\n",
        "summary_df = summary_df.sort_values('Best Val Acc', ascending=False)\n",
        "\n",
        "\n",
        "print(summary_df.to_string(index=False))\n",
        "\n",
        "summary_df.to_csv('yl1_lstm_grid_search_summary.csv', index=False)"
      ],
      "metadata": {
        "id": "hx58vwGZf5GY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"LSTM ON YL1\")\n",
        "\n",
        "lstm_l1, train_losses, train_accuracies, val_accuracies = train_lstm_model(\n",
        "    X_train, y_train_l1, X_val, y_val_l1, vocab, word2vec_wv,\n",
        "    num_classes=len(set(labels_l1)),\n",
        "    embedding_dim = embedding_dim,\n",
        "    hidden_size = 256,\n",
        "    batch_size = 128,\n",
        "    epochs=30,\n",
        "    lr = 0.009,\n",
        "    num_layers = 2,\n",
        "    freeze_embeddings = True,\n",
        "    dropout=0.2\n",
        ")"
      ],
      "metadata": {
        "id": "z108C_0N6hMm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataset_lstm_l1 = WOSDataset(X_test, y_test_l1, vocab)\n",
        "test_loader_lstm_l1 = DataLoader(test_dataset_lstm_l1, batch_size=128, shuffle=False)\n",
        "lstm_l1_acc, _, _ = evaluate_model(lstm_l1, test_loader_lstm_l1, 'LSTM')\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "axes[0].plot(train_losses, linewidth=2, color='#1f77b4', marker='o')\n",
        "axes[0].set_title('Training Loss vs. Epochs')\n",
        "axes[0].set_xlabel('Epochs')\n",
        "axes[0].set_ylabel('Training Loss')\n",
        "axes[0].grid(True, alpha=0.3)\n",
        "\n",
        "axes[1].plot(train_accuracies, label='Train Accuracy', linestyle='-', linewidth=2, color='#1f77b4')\n",
        "axes[1].plot(val_accuracies, label='Validation Accuracy', linestyle='--', linewidth=2, color='#ff7f0e')\n",
        "axes[1].axhline(lstm_l1_acc, label=f'Test Accuracy: {lstm_l1_acc:.2f}', linestyle='--', linewidth=1, color='red')\n",
        "axes[1].set_title('Accuracy vs. Epochs')\n",
        "axes[1].set_xlabel('Epochs')\n",
        "axes[1].set_ylabel('Accuracy')\n",
        "axes[1].legend()\n",
        "axes[1].grid(True, alpha=0.3)\n",
        "\n",
        "# Add best validation accuracy annotation\n",
        "best_val_epoch = np.argmax(val_accuracies)\n",
        "best_val_acc = val_accuracies[best_val_epoch]\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('yl1_lstm.svg')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "rJbDMnIdf8oD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import itertools\n",
        "import pandas as pd\n",
        "\n",
        "print(\"Grid Search for YL2\")\n",
        "# Define hyperparameter grid\n",
        "param_grid = {\n",
        "    'lr': [0.005, 0.009, 0.015],\n",
        "    'num_layers': [1, 2, 3],\n",
        "    'dropout': [0.2, 0.3, 0.5]\n",
        "}\n",
        "\n",
        "# Fixed parameters\n",
        "fixed_params = {\n",
        "    'embedding_dim': embedding_dim,\n",
        "    'hidden_size': 256,\n",
        "    'batch_size': 128,\n",
        "    'epochs': 30,\n",
        "    'freeze_embeddings': True,\n",
        "    'num_classes': len(set(labels_l2))\n",
        "}\n",
        "\n",
        "# Storage for results\n",
        "results = []\n",
        "\n",
        "# Generate all combinations\n",
        "param_combinations = list(itertools.product(\n",
        "    param_grid['lr'],\n",
        "    param_grid['num_layers'],\n",
        "    param_grid['dropout']\n",
        "))\n",
        "\n",
        "total_experiments = len(param_combinations)\n",
        "\n",
        "# Run grid search\n",
        "for idx, (lr, num_layers, dropout) in enumerate(param_combinations, 1):\n",
        "    print(f\"Learning Rate: {lr}\")\n",
        "    print(f\"Num Layers: {num_layers}\")\n",
        "    print(f\"Dropout: {dropout}\")\n",
        "\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "\n",
        "    # Train model\n",
        "\n",
        "    model, train_losses, train_accuracies, val_accuracies = train_lstm_model(\n",
        "        X_train, y_train_l2, X_val, y_val_l2, vocab, word2vec_wv,\n",
        "        num_classes=fixed_params['num_classes'],\n",
        "        embedding_dim=fixed_params['embedding_dim'],\n",
        "        hidden_size=fixed_params['hidden_size'],\n",
        "        batch_size=fixed_params['batch_size'],\n",
        "        epochs=fixed_params['epochs'],\n",
        "        lr=lr,\n",
        "        num_layers=num_layers,\n",
        "        freeze_embeddings=fixed_params['freeze_embeddings'],\n",
        "        dropout=dropout\n",
        "    )\n",
        "\n",
        "\n",
        "    # Get best validation accuracy and corresponding epoch\n",
        "    best_val_acc = max(val_accuracies)\n",
        "    best_epoch = val_accuracies.index(best_val_acc) + 1\n",
        "    final_val_acc = val_accuracies[-1]\n",
        "    final_train_acc = train_accuracies[-1]\n",
        "    final_train_loss = train_losses[-1]\n",
        "\n",
        "    # Store results\n",
        "    result = {\n",
        "        'experiment': idx,\n",
        "        'lr': lr,\n",
        "        'num_layers': num_layers,\n",
        "        'dropout': dropout,\n",
        "        'best_val_acc': best_val_acc,\n",
        "        'best_epoch': best_epoch,\n",
        "        'final_val_acc': final_val_acc,\n",
        "        'final_train_acc': final_train_acc,\n",
        "        'final_train_loss': final_train_loss,\n",
        "        'train_losses': train_losses.copy(),\n",
        "        'train_accuracies': train_accuracies.copy(),\n",
        "        'val_accuracies': val_accuracies.copy(),\n",
        "        'model': model\n",
        "    }\n",
        "\n",
        "    results.append(result)\n",
        "\n",
        "    print(f\"Best Val Acc: {best_val_acc:.4f} (epoch {best_epoch})\")\n",
        "    print(f\"Final Val Acc: {final_val_acc:.4f}\")\n",
        "\n",
        "\n",
        "\n",
        "# Create summary DataFrame\n",
        "summary_df = pd.DataFrame([{\n",
        "    'Experiment': r['experiment'],\n",
        "    'LR': r['lr'],\n",
        "    'Layers': r['num_layers'],\n",
        "    'Dropout': r['dropout'],\n",
        "    'Best Val Acc': r['best_val_acc'],\n",
        "    'Best Epoch': r['best_epoch'],\n",
        "    'Final Val Acc': r['final_val_acc'],\n",
        "    'Final Train Acc': r['final_train_acc']\n",
        "    } for r in results])\n",
        "\n",
        "\n",
        "summary_df = summary_df.sort_values('Best Val Acc', ascending=False)\n",
        "\n",
        "\n",
        "print(summary_df.to_string(index=False))\n",
        "\n",
        "summary_df.to_csv('yl2_lstm_grid_search_summary.csv', index=False)"
      ],
      "metadata": {
        "id": "EJjoTmJsf-oc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"LSTM ON YL2\")\n",
        "\n",
        "lstm_l2, train_losses, train_accuracies, val_accuracies = train_lstm_model(\n",
        "    X_train, y_train_l2, X_val, y_val_l2, vocab, word2vec_wv,\n",
        "    num_classes=len(set(labels_l2)),\n",
        "    embedding_dim = embedding_dim,\n",
        "    hidden_size = 256,\n",
        "    batch_size = 128,\n",
        "    epochs=30,\n",
        "    lr = 0.009,\n",
        "    num_layers = 2,\n",
        "    freeze_embeddings = True,\n",
        "    dropout=0.2\n",
        ")"
      ],
      "metadata": {
        "id": "iOqM92K76i5d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataset_lstm_l2 = WOSDataset(X_test, y_test_l2, vocab)\n",
        "test_loader_lstm_l2 = DataLoader(test_dataset_lstm_l2, batch_size=32, shuffle=False)\n",
        "lstm_l2_acc, _, _ = evaluate_model(lstm_l2, test_loader_lstm_l2, 'LSTM')\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "axes[0].plot(train_losses, linewidth=2, color='#1f77b4', marker='o')\n",
        "axes[0].set_title('Training Loss vs. Epochs')\n",
        "axes[0].set_xlabel('Epochs')\n",
        "axes[0].set_ylabel('Training Loss')\n",
        "axes[0].grid(True, alpha=0.3)\n",
        "\n",
        "axes[1].plot(train_accuracies, label='Train Accuracy', linestyle='-', linewidth=2, color='#1f77b4')\n",
        "axes[1].plot(val_accuracies, label='Validation Accuracy', linestyle='--', linewidth=2, color='#ff7f0e')\n",
        "axes[1].axhline(lstm_l2_acc, label=f'Test Accuracy: {lstm_l2_acc:.2f}', linestyle='--', linewidth=1, color='red')\n",
        "axes[1].set_title('Accuracy vs. Epochs')\n",
        "axes[1].set_xlabel('Epochs')\n",
        "axes[1].set_ylabel('Accuracy')\n",
        "axes[1].legend()\n",
        "axes[1].grid(True, alpha=0.3)\n",
        "\n",
        "# Add best validation accuracy annotation\n",
        "best_val_epoch = np.argmax(val_accuracies)\n",
        "best_val_acc = val_accuracies[best_val_epoch]\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('yl2_lstm.svg')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Ow8gkV1jgBm2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"LSTM ON Y COMBINED\")\n",
        "\n",
        "lstm_lc, train_losses, train_accuracies, val_accuracies = train_lstm_model(\n",
        "    X_train, y_train_combo, X_val, y_val_combo, vocab, word2vec_wv,\n",
        "    num_classes=len(set(merged_labels)),\n",
        "    embedding_dim = embedding_dim,\n",
        "    hidden_size = 256,\n",
        "    batch_size = 128,\n",
        "    epochs=30,\n",
        "    lr = 0.009,\n",
        "    num_layers = 2,\n",
        "    freeze_embeddings = True,\n",
        "    dropout=0.2\n",
        ")"
      ],
      "metadata": {
        "id": "S-vv0m2t6kxC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KHKj8tG-Y2jx"
      },
      "outputs": [],
      "source": [
        "test_dataset_lstm_combo= WOSDataset(X_test, y_test_combo, vocab)\n",
        "test_loader_lstm_combo = DataLoader(test_dataset_lstm_combo, batch_size=32, shuffle=False)\n",
        "lstm_lc_acc, _, _ = evaluate_model(lstm_lc, test_loader_lstm_combo, 'LSTM')\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "axes[0].plot(train_losses, linewidth=2, color='#1f77b4', marker='o')\n",
        "axes[0].set_title('Training Loss vs. Epochs')\n",
        "axes[0].set_xlabel('Epochs')\n",
        "axes[0].set_ylabel('Training Loss')\n",
        "axes[0].grid(True, alpha=0.3)\n",
        "\n",
        "axes[1].plot(train_accuracies, label='Train Accuracy', linestyle='-', linewidth=2, color='#1f77b4')\n",
        "axes[1].plot(val_accuracies, label='Validation Accuracy', linestyle='--', linewidth=2, color='#ff7f0e')\n",
        "axes[1].axhline(lstm_lc_acc, label=f'Test Accuracy: {lstm_lc_acc:.2f}', linestyle='--', linewidth=1, color='red')\n",
        "axes[1].set_title('Accuracy vs. Epochs')\n",
        "axes[1].set_xlabel('Epochs')\n",
        "axes[1].set_ylabel('Accuracy')\n",
        "axes[1].legend()\n",
        "axes[1].grid(True, alpha=0.3)\n",
        "\n",
        "best_val_epoch = np.argmax(val_accuracies)\n",
        "best_val_acc = val_accuracies[best_val_epoch]\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('y_combo_lstm.svg')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# BERT Grid Search and Training"
      ],
      "metadata": {
        "id": "z9hCcAPKg0AJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gc\n",
        "import itertools\n",
        "\n",
        "print(\"Grid Search for BERT parameters\")\n",
        "\n",
        "param_grid = {\n",
        "    'learning_rate': [2e-5, 5e-5],\n",
        "    'dropout': [0.1, 0.3, 0.5]\n",
        "}\n",
        "\n",
        "param_combinations = list(itertools.product(\n",
        "    param_grid['learning_rate'],\n",
        "    param_grid['dropout']\n",
        "))\n",
        "\n",
        "\n",
        "results_data = []\n",
        "\n",
        "for i, (lr, dropout) in enumerate(param_combinations, 1):\n",
        "    print(f\"Learning rate: {lr}, Dropout: {dropout}\")\n",
        "\n",
        "    # Clean up memory\n",
        "    try:\n",
        "        del bert_model, train_loader, val_loader, tokenizer\n",
        "        del all_losses, train_losses, val_accuracies, train_accuracies\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "    gc.collect()\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "    bert_model, train_loader, val_loader, tokenizer, all_losses, train_losses, val_accuracies, train_accuracies = train_bert_model(\n",
        "        X_train, y_train_l1, X_val, y_val_l1,\n",
        "        num_classes=len(set(labels_l1)),\n",
        "        batch_size=16,\n",
        "        epochs=5,\n",
        "        learning_rate=lr,\n",
        "        dropout=dropout\n",
        "    )\n",
        "\n",
        "    # Store results for each epoch\n",
        "    for epoch in range(len(train_accuracies)):\n",
        "        results_data.append({\n",
        "            'experiment': i,\n",
        "            'learning_rate': lr,\n",
        "            'dropout': dropout,\n",
        "            'epoch': epoch + 1,\n",
        "            'train_accuracy': train_accuracies[epoch],\n",
        "            'val_accuracy': val_accuracies[epoch]\n",
        "        })\n",
        "\n",
        "\n",
        "df_results = pd.DataFrame(results_data)\n",
        "\n",
        "df_results = df_results.sort_values('val_accuracy', ascending=False)\n",
        "\n",
        "df_results.to_csv('bert_grid_search_results.csv', index=False)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "CgpxqkrZgKJ3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Delete any existing models/variables\n",
        "try:\n",
        "    del bert_l1, train_loader, val_loader, tokenizer\n",
        "    del all_losses, train_losses, val_accuracies, train_accuracies\n",
        "except:\n",
        "    pass\n",
        "\n",
        "# Force garbage collection\n",
        "import gc\n",
        "gc.collect()\n",
        "\n",
        "# Clear GPU cache\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "# Now train\n",
        "print(\"BERT ON YL1\")\n",
        "bert_l1, train_loader, val_loader, tokenizer, all_losses, train_losses, val_accuracies, train_accuracies = train_bert_model(\n",
        "    X_train, y_train_l1, X_val, y_val_l1,\n",
        "    num_classes=len(set(labels_l1)),\n",
        "    batch_size=16,\n",
        "    epochs=5,\n",
        "    learning_rate=5e-5,\n",
        "    dropout=0.1\n",
        ")\n",
        "import pickle\n",
        "\n",
        "filename = 'bert_model.pkl'\n",
        "with open(filename, 'wb') as file:\n",
        "    pickle.dump(bert_l1, file)"
      ],
      "metadata": {
        "id": "HL27vnw2gOFN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataset_bert_l1= WOSDatasetBERT(X_test, y_test_l1, tokenizer)\n",
        "test_loader_bert_l1 = DataLoader(test_dataset_bert_l1, batch_size=16, shuffle=False)\n",
        "lstm_lc_acc, _, _ = evaluate_model(bert_l1, test_loader_bert_l1, 'BERT')\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "axes[0].plot(train_losses, linewidth=2, color='#1f77b4', marker='o')\n",
        "axes[0].set_title('Training Loss vs. Epochs')\n",
        "axes[0].set_xlabel('Epochs')\n",
        "axes[0].set_ylabel('Training Loss')\n",
        "axes[0].grid(True, alpha=0.3)\n",
        "\n",
        "axes[1].plot(train_accuracies, label='Train Accuracy', linestyle='-', linewidth=2, color='#1f77b4')\n",
        "axes[1].plot(val_accuracies, label='Validation Accuracy', linestyle='--', linewidth=2, color='#ff7f0e')\n",
        "axes[1].axhline(lstm_lc_acc, label=f'Test Accuracy: {lstm_lc_acc:.2f}', linestyle='--', linewidth=1, color='red')\n",
        "axes[1].set_title('Accuracy vs. Epochs')\n",
        "axes[1].set_xlabel('Epochs')\n",
        "axes[1].set_ylabel('Accuracy')\n",
        "axes[1].legend()\n",
        "axes[1].grid(True, alpha=0.3)\n",
        "\n",
        "best_val_epoch = np.argmax(val_accuracies)\n",
        "best_val_acc = val_accuracies[best_val_epoch]\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('y_l1_bert.svg')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "03_oE_cwgPnF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"BERT ON YL2\")\n",
        "bert_l2, train_loader, val_loader, tokenizer, all_losses, train_losses, val_accuracies, train_accuracies = train_bert_model(\n",
        "    X_train, y_train_l2, X_val, y_val_l2,\n",
        "    num_classes=len(set(labels_l2)),\n",
        "    batch_size=16,\n",
        "    epochs=5,\n",
        "    learning_rate=5e-5,\n",
        "    dropout=0.1\n",
        ")"
      ],
      "metadata": {
        "id": "RIarbGaCgRJF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataset_bert_l2= WOSDatasetBERT(X_test, y_test_l2, tokenizer)\n",
        "test_loader_bert_l2 = DataLoader(test_dataset_bert_l2, batch_size=16, shuffle=False)\n",
        "bert_acc, _, _ = evaluate_model(bert_l2, test_loader_bert_l2, 'BERT')\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "axes[0].plot(train_losses, linewidth=2, color='#1f77b4', marker='o')\n",
        "axes[0].set_title('Training Loss vs. Epochs')\n",
        "axes[0].set_xlabel('Epochs')\n",
        "axes[0].set_ylabel('Training Loss')\n",
        "axes[0].grid(True, alpha=0.3)\n",
        "\n",
        "axes[1].plot(train_accuracies, label='Train Accuracy', linestyle='-', linewidth=2, color='#1f77b4')\n",
        "axes[1].plot(val_accuracies, label='Validation Accuracy', linestyle='--', linewidth=2, color='#ff7f0e')\n",
        "axes[1].axhline(bert_acc, label=f'Test Accuracy: {bert_acc:.2f}', linestyle='--', linewidth=1, color='red')\n",
        "axes[1].set_title('Accuracy vs. Epochs')\n",
        "axes[1].set_xlabel('Epochs')\n",
        "axes[1].set_ylabel('Accuracy')\n",
        "axes[1].legend()\n",
        "axes[1].grid(True, alpha=0.3)\n",
        "\n",
        "best_val_epoch = np.argmax(val_accuracies)\n",
        "best_val_acc = val_accuracies[best_val_epoch]\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('y_l2_bert.svg')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "kWTmdO8agRww"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"BERT ON Y COMBINED\")\n",
        "bert_lcombo, train_loader, val_loader, tokenizer, all_losses, train_losses, val_accuracies, train_accuracies = train_bert_model(\n",
        "    X_train, y_train_combo, X_val, y_val_combo,\n",
        "    num_classes=len(set(merged_labels)),\n",
        "    batch_size=16,\n",
        "    epochs=5,\n",
        "    learning_rate=5e-5,\n",
        "    dropout=0.1\n",
        ")"
      ],
      "metadata": {
        "id": "gFWQiuRAgT8L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataset_bert_lcombo= WOSDatasetBERT(X_test, y_test_combo, tokenizer)\n",
        "test_loader_bert_lcombo = DataLoader(test_dataset_bert_lcombo, batch_size=16, shuffle=False)\n",
        "lstm_lc_acc, _, _ = evaluate_model(bert_lcombo, test_loader_bert_lcombo, 'BERT')\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "axes[0].plot(train_losses, linewidth=2, color='#1f77b4', marker='o')\n",
        "axes[0].set_title('Training Loss vs. Epochs')\n",
        "axes[0].set_xlabel('Epochs')\n",
        "axes[0].set_ylabel('Training Loss')\n",
        "axes[0].grid(True, alpha=0.3)\n",
        "\n",
        "axes[1].plot(train_accuracies, label='Train Accuracy', linestyle='-', linewidth=2, color='#1f77b4')\n",
        "axes[1].plot(val_accuracies, label='Validation Accuracy', linestyle='--', linewidth=2, color='#ff7f0e')\n",
        "axes[1].axhline(lstm_lc_acc, label=f'Test Accuracy: {lstm_lc_acc:.2f}', linestyle='--', linewidth=1, color='red')\n",
        "axes[1].set_title('Accuracy vs. Epochs')\n",
        "axes[1].set_xlabel('Epochs')\n",
        "axes[1].set_ylabel('Accuracy')\n",
        "axes[1].legend()\n",
        "axes[1].grid(True, alpha=0.3)\n",
        "\n",
        "best_val_epoch = np.argmax(val_accuracies)\n",
        "best_val_acc = val_accuracies[best_val_epoch]\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('y_combo_bert.svg')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "GdRKuqj0gVHW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Visualising BERT Attention Matrices"
      ],
      "metadata": {
        "id": "ycKQcyEtg3Ow"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Attention Visualization\n",
        "\n",
        "stopwords = {\n",
        "    'the', 'a', 'an', 'and', 'or', 'but', 'in', 'on', 'at', 'to', 'for',\n",
        "    'of', 'with', 'by', 'from', 'as', 'is', 'was', 'are', 'were', 'be',\n",
        "    'been', 'being', 'have', 'has', 'had', 'do', 'does', 'did', 'will',\n",
        "    'would', 'should', 'could', 'may', 'might', 'must', 'can', 'this',\n",
        "    'that', 'these', 'those', 'i', 'you', 'he', 'she', 'it', 'we', 'they',\n",
        "    'my', 'your', 'his', 'her', 'its', 'our', 'their', 'me', 'him', 'them',\n",
        "    'us', 'what', 'which', 'who', 'when', 'where', 'why', 'how'\n",
        "}\n",
        "\n",
        "label_names = {\n",
        "    0: 'Computer Science',\n",
        "    1: 'Electrical Engineering',\n",
        "    2: 'Psychology',\n",
        "    3: 'Mechanical Engineering',\n",
        "    4: 'Civil Engineering',\n",
        "    5: 'Medical Science',\n",
        "    6: 'Biochemistry'\n",
        "}\n",
        "\n",
        "\n",
        "def analyze_attention_patterns(model, test_loader, tokenizer, num_samples=3):\n",
        "    model.eval()\n",
        "    correct_samples = []\n",
        "    incorrect_samples = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in test_loader:\n",
        "            input_ids = batch['input_ids'].to(model.device)\n",
        "            attention_mask = batch['attention_mask'].to(model.device)\n",
        "            labels = batch['labels'].to(model.device)\n",
        "\n",
        "            outputs = model(input_ids, attention_mask=attention_mask)\n",
        "            predictions = torch.argmax(outputs, dim=1)\n",
        "\n",
        "            for i in range(len(predictions)):\n",
        "\n",
        "                text = tokenizer.decode(input_ids[i], skip_special_tokens=True)\n",
        "                true_label = labels[i].item()\n",
        "                pred_label = predictions[i].item()\n",
        "\n",
        "                if pred_label == true_label and len(correct_samples) < num_samples:\n",
        "                    correct_samples.append((text, true_label, pred_label))\n",
        "                elif pred_label != true_label and len(incorrect_samples) < num_samples:\n",
        "                    incorrect_samples.append((text, true_label, pred_label))\n",
        "\n",
        "                if len(correct_samples) >= num_samples and len(incorrect_samples) >= num_samples:\n",
        "                    return correct_samples, incorrect_samples\n",
        "\n",
        "    return correct_samples, incorrect_samples\n",
        "\n",
        "def get_aggregate_attention(model, text, tokenizer):\n",
        "    model.eval()\n",
        "\n",
        "    encoding = tokenizer.encode_plus(\n",
        "        text,\n",
        "        add_special_tokens=True,\n",
        "        max_length=128,\n",
        "        padding='max_length',\n",
        "        truncation=True,\n",
        "        return_attention_mask=True,\n",
        "        return_tensors='pt'\n",
        "    )\n",
        "\n",
        "    input_ids = encoding['input_ids'].to(model.device)\n",
        "    attention_mask = encoding['attention_mask'].to(model.device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        _, attentions = model.forward(input_ids, attention_mask, return_attention=True)\n",
        "\n",
        "    all_attentions = torch.stack([att for att in attentions])\n",
        "    all_attentions = all_attentions.squeeze(1)\n",
        "\n",
        "    aggregate = all_attentions.mean(dim=[0, 1])\n",
        "\n",
        "    return aggregate.cpu().numpy(), encoding\n",
        "\n",
        "def visualize_attention_heatmap(model, text, label, tokenizer, prediction, ):\n",
        "    aggregate_attention, encoding = get_aggregate_attention(model, text, tokenizer)\n",
        "\n",
        "    tokens = tokenizer.convert_ids_to_tokens(encoding['input_ids'][0].cpu().numpy())\n",
        "    attention_mask = encoding['attention_mask'][0]\n",
        "    valid_length = attention_mask.sum().item()\n",
        "\n",
        "    tokens = tokens[:valid_length]\n",
        "    attention = aggregate_attention[:valid_length, :valid_length]\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(10, 10))\n",
        "    im = ax.imshow(attention, cmap='viridis')\n",
        "\n",
        "    ax.set_xticks(range(len(tokens)))\n",
        "    ax.set_yticks(range(len(tokens)))\n",
        "    ax.set_xticklabels(tokens, rotation=90)\n",
        "    ax.set_yticklabels(tokens)\n",
        "\n",
        "    plt.colorbar(im, ax=ax)\n",
        "    plt.title(f'Average Attention Matrix \\nTrue: {label_names[label]}, Predicted: {label_names[prediction]}')\n",
        "    plt.tight_layout()\n",
        "\n",
        "    return fig\n",
        "\n",
        "\n",
        "def visualize_content_words(model, text, label, tokenizer, prediction, layer_idx=11, top_n=15):\n",
        "    model.eval()\n",
        "\n",
        "    encoding = tokenizer.encode_plus(\n",
        "        text,\n",
        "        add_special_tokens=True,\n",
        "        max_length=128,\n",
        "        padding='max_length',\n",
        "        truncation=True,\n",
        "        return_attention_mask=True,\n",
        "        return_tensors='pt'\n",
        "    )\n",
        "\n",
        "    input_ids = encoding['input_ids'].to(model.device)\n",
        "    attention_mask = encoding['attention_mask'].to(model.device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        _, attentions = model.forward(input_ids, attention_mask, return_attention=True)\n",
        "\n",
        "    attention = attentions[layer_idx][0].mean(dim=0).cpu().numpy()\n",
        "    tokens = tokenizer.convert_ids_to_tokens(input_ids[0].cpu().numpy())\n",
        "\n",
        "    valid_length = attention_mask[0].sum().item()\n",
        "    tokens = tokens[:valid_length]\n",
        "    attention = attention[:valid_length, :valid_length]\n",
        "\n",
        "    attention_received = attention.sum(axis=0)\n",
        "\n",
        "    content_tokens = []\n",
        "    content_attention = []\n",
        "\n",
        "    for token, score in zip(tokens, attention_received):\n",
        "        clean_token = token.replace('##', '').lower()\n",
        "        if token not in ['[CLS]', '[SEP]', '[PAD]'] and clean_token not in stopwords:\n",
        "            content_tokens.append(token)\n",
        "            content_attention.append(score)\n",
        "\n",
        "    if not content_tokens:\n",
        "        return None\n",
        "\n",
        "    sorted_idx = np.argsort(content_attention)[::-1][:top_n]\n",
        "    top_tokens = [content_tokens[i] for i in sorted_idx]\n",
        "    top_attention = [content_attention[i] for i in sorted_idx]\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(8, 6))\n",
        "    ax.barh(range(len(top_tokens)), top_attention)\n",
        "    ax.set_yticks(range(len(top_tokens)))\n",
        "    ax.set_yticklabels(top_tokens)\n",
        "    ax.set_xlabel('Attention Score')\n",
        "    ax.set_title(f'Top {top_n} Content Words\\nTrue: {label_names[label]}, Predicted: {label_names[prediction]}')\n",
        "    ax.invert_yaxis()\n",
        "\n",
        "    plt.tight_layout()\n",
        "\n",
        "    return fig"
      ],
      "metadata": {
        "id": "2JnWPmTWgWfW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "\n",
        "test_dataset_bert_l1 = WOSDatasetBERT(X_val, y_val_l1, tokenizer)\n",
        "test_loader_bert_l1 = DataLoader(test_dataset_bert_l1, batch_size=32, shuffle=True)\n",
        "\n",
        "with open('bert_model.pkl', 'rb') as file:\n",
        "    bert_l1 = pickle.load(file)\n",
        "\n",
        "correct_samples, incorrect_samples = analyze_attention_patterns(bert_l1, test_loader_bert_l1, tokenizer, num_samples=3)\n",
        "\n",
        "# Correct predictions\n",
        "print(\"Correct Predictions\")\n",
        "\n",
        "for i, (text, true_label, pred_label) in enumerate(correct_samples):\n",
        "\n",
        "    fig = visualize_attention_heatmap(bert_l1, text, true_label, tokenizer, pred_label)\n",
        "    # plt.savefig(f\"correct_attention_bert_{i}.svg\")\n",
        "    plt.show()\n",
        "\n",
        "    fig = visualize_content_words(bert_l1, text, true_label, tokenizer, pred_label, top_n=15)\n",
        "    # plt.savefig(f\"correct_words_bert_{i}.svg\")\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "print(\"Incorrect Predictions\")\n",
        "for i, (text, true_label, pred_label) in enumerate(incorrect_samples):\n",
        "\n",
        "    fig = visualize_attention_heatmap(bert_l1, text, true_label, tokenizer, pred_label)\n",
        "    # plt.savefig(f\"incorrect_attention_bert_{i}.svg\")\n",
        "    plt.show()\n",
        "\n",
        "    fig = visualize_content_words(bert_l1, text, true_label, tokenizer, pred_label, top_n=15)\n",
        "    # plt.savefig(f\"incorrect_words_bert_{i}.svg\")\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "HgESxJi2gXIT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Extension: Compare Word2Vec Initialisation and Random Initialisation"
      ],
      "metadata": {
        "id": "AF9S5k0Ig8nB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "\n",
        "\n",
        "# Compare Word2Vec initialization vs random initialization\n",
        "\n",
        "\n",
        "print(\"Word2Vec vs Random Initialization\")\n",
        "\n",
        "train_dataset = WOSDataset(X_train, y_train_l1, vocab)\n",
        "val_dataset = WOSDataset(X_val, y_val_l1, vocab)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=128, shuffle=False)\n",
        "\n",
        "# Model with Word2Vec\n",
        "print(\"Training with Word2Vec embeddings\")\n",
        "embedding_matrix = build_embedding_matrix(vocab, word2vec_wv, 150)\n",
        "model_w2v = LSTMModel(\n",
        "    vocab_size=len(vocab),\n",
        "    embedding_dim=150,\n",
        "    hidden_size=128,\n",
        "    num_classes=len(set(labels_l1)),\n",
        "    embedding_matrix=embedding_matrix,\n",
        "    freeze_embeddings=True,\n",
        "    num_layers=2,\n",
        "    dropout=0.2\n",
        ")\n",
        "\n",
        "train_losses_w2v, train_accuracies_w2v, val_accuracies_w2v = model_w2v.fit(train_loader,\n",
        "                                                                           val_loader,\n",
        "                                                                           epochs=30,\n",
        "                                                                           lr=0.009\n",
        "                                                                           )\n",
        "final_acc_w2v = model_w2v.evaluate_acc(val_loader)\n",
        "\n",
        "# Model with random initialization\n",
        "print(\"Training with random initialization\")\n",
        "model_random = LSTMModel(\n",
        "    vocab_size=len(vocab),\n",
        "    embedding_dim=150,\n",
        "    hidden_size=128,\n",
        "    num_classes=len(set(labels_l1)),\n",
        "    embedding_matrix=None, # Random Initialisation\n",
        "    freeze_embeddings=False\n",
        ")\n",
        "\n",
        "train_losses_random , train_accuracies_random , val_accuracies_random = model_random.fit(train_loader,\n",
        "                                                                                         val_loader,\n",
        "                                                                                         epochs=30,\n",
        "                                                                                         lr=0.009\n",
        "                                                                                         )\n",
        "final_acc_random = model_random.evaluate_acc(val_loader)\n",
        "\n",
        "\n",
        "print(\"Word2Vec initialization:\", final_acc_w2v)\n",
        "print(\"Random initialization:\", final_acc_random)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ctvefjwkgYlQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, axes = plt.subplots(1, 3, figsize=(18, 5), gridspec_kw={'width_ratios': [1, 1.5, 0.8]})\n",
        "\n",
        "# Plot 1: Training Loss Comparison\n",
        "axes[0].plot(train_losses_w2v, label='Word2Vec Initialization', linewidth=2, color='#1f77b4')\n",
        "axes[0].plot(train_losses_random, label='Random Initialization', linewidth=2, color='#ff7f0e')\n",
        "axes[0].set_title('Training Loss vs. Epochs')\n",
        "axes[0].set_xlabel('Epochs')\n",
        "axes[0].set_ylabel('Training Loss')\n",
        "axes[0].legend()\n",
        "axes[0].grid(True, alpha=0.3)\n",
        "\n",
        "axes[1].plot(train_accuracies_w2v, label='Train: Word2Vec', linestyle='-', linewidth=2, color='#1f77b4')\n",
        "axes[1].plot(val_accuracies_w2v, label='Validation: Word2Vec', linestyle='--', linewidth=2, color='#1f77b4')\n",
        "axes[1].plot(train_accuracies_random, label='Train: Random', linestyle='-', linewidth=2, color='#ff7f0e')\n",
        "axes[1].plot(val_accuracies_random, label='Validation: Random', linestyle='--', linewidth=2, color='#ff7f0e')\n",
        "axes[1].set_title('Accuracy vs. Epochs')\n",
        "axes[1].set_xlabel('Epochs')\n",
        "axes[1].set_ylabel('Accuracy')\n",
        "axes[1].legend()\n",
        "axes[1].grid(True, alpha=0.3)\n",
        "\n",
        "# Plot 3: Final Validation Accuracy Comparison (Bar chart)\n",
        "methods = ['Word2Vec\\nInitialisation', 'Random\\nInitilisation']\n",
        "final_accs = [final_acc_w2v, final_acc_random]\n",
        "colors_bar = ['#1f77b4', '#ff7f0e']\n",
        "\n",
        "bars = axes[2].bar(methods, final_accs, color=colors_bar, width=0.5)\n",
        "axes[2].set_title('Final Validation Accuracy')\n",
        "axes[2].set_ylabel('Accuracy')\n",
        "axes[2].set_ylim([min(final_accs) - 0.15, max(final_accs) + 0.05])\n",
        "\n",
        "# Add value labels on bars\n",
        "for i, (bar, acc) in enumerate(zip(bars, final_accs)):\n",
        "    axes[2].text(bar.get_x() + bar.get_width()/2, acc + 0.005, f'{acc:.4f}', ha='center', va='bottom')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(\"word2vec_vs_random_initialisation.svg\", bbox_inches='tight')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "rEZoImdVgbMM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Extension: Embedding Dimension"
      ],
      "metadata": {
        "id": "XaQMK8H6hB3U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Embedding Dimension\")\n",
        "\n",
        "dimensions = [50, 100, 150, 200, 250, 300]\n",
        "results = []\n",
        "\n",
        "for dim in dimensions:\n",
        "    print(\"Testing embedding dimension:\", dim)\n",
        "\n",
        "    data_path = \"WebOfScience/WOS11967/\"\n",
        "\n",
        "    texts, labels_l1, labels_l2, merged_labels = load_data(data_path)\n",
        "    print(f\"Loaded {len(texts)} documents\")\n",
        "    print(f\"YL1 classes: {len(set(labels_l1))}, YL2 classes: {len(set(labels_l2))}\")\n",
        "    print(f\"Merged Y classes: {len(set(merged_labels))}\")\n",
        "\n",
        "    texts = [clean_text(t) for t in texts]\n",
        "    sentences = [text.lower().split() for text in texts]\n",
        "\n",
        "\n",
        "    w2v_model = Word2Vec(sentences=sentences, vector_size=dim, window=6, min_count=0, workers=8, epochs=10, sg=1)\n",
        "\n",
        "    embedding_matrix = build_embedding_matrix(vocab, w2v_model.wv, dim)\n",
        "\n",
        "    train_dataset = WOSDataset(X_train, y_train_l1, vocab)\n",
        "    val_dataset = WOSDataset(X_val, y_val_l1, vocab)\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=128, shuffle=False)\n",
        "\n",
        "    model = LSTMModel(\n",
        "        vocab_size=len(vocab),\n",
        "        embedding_dim=dim,\n",
        "        hidden_size=128,\n",
        "        num_classes=len(set(labels_l1)),\n",
        "        embedding_matrix=embedding_matrix,\n",
        "        freeze_embeddings=True,\n",
        "        num_layers=2,\n",
        "        dropout=0.2\n",
        "    )\n",
        "\n",
        "    train_losses, train_accs, val_accs = model.fit(train_loader, val_loader, epochs=30, lr=0.009)\n",
        "    best_val_acc = np.max(val_accs)\n",
        "    final_val_acc = val_accs[-1]\n",
        "    n_params = sum(p.numel() for p in model.parameters())\n",
        "\n",
        "    results.append({\n",
        "        'Dimension': dim,\n",
        "        'Accuracy': best_val_acc,\n",
        "        'Parameters': n_params\n",
        "    })\n",
        "\n",
        "    print(f\"Accuracy:\", best_val_acc)\n",
        "\n",
        "df = pd.DataFrame(results)\n",
        "\n"
      ],
      "metadata": {
        "id": "5w7byvKWgcva"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax1 = plt.subplots(figsize=(10, 6))\n",
        "\n",
        "ax1.plot(df['Dimension'], df['Accuracy'], 'b-o', linewidth=2)\n",
        "ax1.set_xlabel('Embedding Dimension')\n",
        "ax1.set_ylabel('Validation Accuracy', color='b')\n",
        "ax1.tick_params(axis='y', labelcolor='b')\n",
        "ax1.grid(True, alpha=0.3)\n",
        "\n",
        "ax2 = ax1.twinx()\n",
        "ax2.plot(df['Dimension'], df['Parameters'], 'r--s', linewidth=2)\n",
        "ax2.set_ylabel('Number of Parameters', color='r')\n",
        "ax2.tick_params(axis='y', labelcolor='r')\n",
        "\n",
        "plt.title('Effect of Embedding Dimension on LSTM Performance')\n",
        "plt.tight_layout()\n",
        "plt.savefig('embedding_dim_effect.svg')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "dX8v7gYfgecG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Extension: Input Sequence Length"
      ],
      "metadata": {
        "id": "f83hccaIhEYV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "print(\"Input Sequence Length Analysis\")\n",
        "\n",
        "sequence_lengths = [50, 100, 150, 200, 250, 300, 350]\n",
        "results = []\n",
        "\n",
        "data_path = \"WebOfScience/WOS11967/\"\n",
        "\n",
        "texts, labels_l1, labels_l2, merged_labels = load_data(data_path)\n",
        "print(f\"Loaded {len(texts)} documents\")\n",
        "print(f\"YL1 classes: {len(set(labels_l1))}, YL2 classes: {len(set(labels_l2))}\")\n",
        "print(f\"Merged Y classes: {len(set(merged_labels))}\")\n",
        "\n",
        "sentences = [text.lower().split() for text in X_train]\n",
        "\n",
        "\n",
        "print(\"Training Word2Vec model\")\n",
        "w2v_model = Word2Vec(sentences=sentences, vector_size=150, window=5, min_count=2, workers=4, epochs=10, sg=1)\n",
        "embedding_matrix = build_embedding_matrix(vocab, w2v_model.wv, 150)\n",
        "\n",
        "for seq_len in sequence_lengths:\n",
        "    print(\"Testing sequence_length: \", seq_len)\n",
        "\n",
        "    train_dataset = WOSDataset(X_train, y_train_l1, vocab, max_len=seq_len)\n",
        "    val_dataset = WOSDataset(X_val, y_val_l1, vocab, max_len=seq_len)\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=128, shuffle=False)\n",
        "\n",
        "    model = LSTMModel(\n",
        "        vocab_size=len(vocab),\n",
        "        embedding_dim=150,\n",
        "        hidden_size=128,\n",
        "        num_classes=len(set(labels_l1)),\n",
        "        embedding_matrix=embedding_matrix,\n",
        "        freeze_embeddings=True,\n",
        "        num_layers=2,\n",
        "        dropout=0.2\n",
        "    )\n",
        "\n",
        "    start_time = time.time()\n",
        "    train_losses, train_accs, val_accs = model.fit(train_loader,\n",
        "                                                   val_loader,\n",
        "                                                   epochs=30,\n",
        "                                                   lr=0.009)\n",
        "    training_time = time.time() - start_time\n",
        "\n",
        "    final_train_acc = train_accs[-1]\n",
        "    final_val_acc = val_accs[-1]\n",
        "    best_val_acc = np.max(val_accs)\n",
        "    n_params = sum(p.numel() for p in model.parameters())\n",
        "\n",
        "    # Calculate average text length coverage\n",
        "    text_lengths = [len(text.lower().split()) for text in X_train]\n",
        "    coverage = sum(1 for length in text_lengths if length <= seq_len) / len(text_lengths) * 100\n",
        "\n",
        "    results.append({\n",
        "        'Sequence Length': seq_len,\n",
        "        'Train Accuracy': final_train_acc,\n",
        "        'Val Accuracy': final_val_acc,\n",
        "        'Best Val Accuracy': best_val_acc,\n",
        "        'Parameters': n_params,\n",
        "        'Text Coverage': coverage,\n",
        "        'Training Time': training_time/60\n",
        "    })\n",
        "\n",
        "\n",
        "\n",
        "df_seq_len = pd.DataFrame(results)\n",
        "df_seq_len.to_csv(\"df_seq_len.csv\", index=False)\n",
        "\n"
      ],
      "metadata": {
        "id": "OjC19_wZggv5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df_seq_len.to_string(index=False))\n",
        "\n",
        "\n",
        "# Plotting\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "# Plot 1: Accuracy vs Sequence Length\n",
        "axes[0].plot(df_seq_len['Sequence Length'], df_seq_len['Train Accuracy'],\n",
        "                marker='o', linewidth=2, label='Train Accuracy', color='#1f77b4')\n",
        "axes[0].plot(df_seq_len['Sequence Length'], df_seq_len['Val Accuracy'],\n",
        "                marker='s', linewidth=2, label='Validation Accuracy', color='#ff7f0e')\n",
        "axes[0].set_xlabel('Sequence Length')\n",
        "axes[0].set_ylabel('Accuracy')\n",
        "axes[0].set_title('Effect of Sequence Length on LSTM Accuracy')\n",
        "axes[0].legend()\n",
        "axes[0].grid(True, alpha=0.3)\n",
        "\n",
        "text_lengths = [len(text.lower().split()) for text in X_train]\n",
        "\n",
        "axes[1].hist(text_lengths, bins=50, alpha=0.7, color='#1f77b4', edgecolor='black')\n",
        "colors = ['#d62728', '#ff7f0e', '#2ca02c', '#9467bd', '#8c564b', \"#1533b9\",  \"#c81cce\"]\n",
        "\n",
        "for i, seq_len in enumerate(sequence_lengths):\n",
        "    axes[1].axvline(x=seq_len, color=colors[i], linestyle='--', linewidth=2,\n",
        "                label=f'Sequence Length: {seq_len}')\n",
        "\n",
        "axes[1].set_xlabel('Text Length (words)')\n",
        "axes[1].set_ylabel('Frequency')\n",
        "axes[1].set_title('Distribution of Text Lengths in Training Set')\n",
        "axes[1].legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(\"sequence_length_analysis.svg\", bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "percentiles = [25, 50, 75, 90, 95, 99]\n",
        "print(\"\\nPercentiles:\")\n",
        "for p in percentiles:\n",
        "    val = np.percentile(text_lengths, p)\n",
        "    print(f\"  {p}th percentile: {val:.0f} words\")"
      ],
      "metadata": {
        "id": "4x7cscIZgiOu"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}